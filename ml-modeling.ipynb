{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "pd.set_option('max_columns', 999)\n",
    "pd.set_option('max_rows', 250)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# magic word for producing visualizations in notebook\n",
    "%matplotlib inline\n",
    "\n",
    "seed = 60611\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_named_columns(col):\n",
    "    \"\"\"\n",
    "    Removes columns from DataFrame while loaded that are unnamed\n",
    "    \"\"\"\n",
    "    return 'Unnamed' not in col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = pd.read_excel('data/DIAS Attributes - Values 2017.xlsx', header=1, usecols=only_named_columns)\n",
    "attributes[['Attribute', 'Description']] = attributes[['Attribute', 'Description']].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "mailout_test = pd.read_csv('data/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';')\n",
    "\n",
    "mailout_train = pd.read_csv('data/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the dataframe pipeline\n",
    "def clean_dataframe(df, attributes, drop_cols, missingness_cols):\n",
    "    def clean_columns_18_19(df):\n",
    "        columns = ['CAMEO_DEUG_2015', 'CAMEO_INTL_2015']\n",
    "        df[columns] = df.loc[:, columns].replace(['X', 'XX'], np.nan)\n",
    "        df[columns] = df.loc[:, columns].astype(float)\n",
    "        return df\n",
    "    def ost_west_encoder(df):\n",
    "        encoder = {\n",
    "            'O': 0,\n",
    "            'W': 1\n",
    "        }\n",
    "        df['OST_WEST_KZ'] = df['OST_WEST_KZ'].map(encoder)\n",
    "        return df\n",
    "    def male_encoder(df):\n",
    "        encoder = {\n",
    "            2: 0,\n",
    "            1: 1\n",
    "        }\n",
    "        df['ANREDE_KZ'] = df['ANREDE_KZ'].map(encoder)\n",
    "        return df\n",
    "    def one_hot_encode(df, col, drop_first=False):\n",
    "        dummies = pd.get_dummies(df[col], drop_first=drop_first)\n",
    "        df_list = [df.drop(col, axis=1), dummies]\n",
    "        return pd.concat(df_list, axis=1)\n",
    "    def lookup_unknown_val(col, attributes):\n",
    "        try:\n",
    "            mask = (attributes['Attribute'] == col) & (attributes['Meaning'].str.startswith('unknown'))\n",
    "            unknown_val = attributes.loc[mask, 'Value']\n",
    "            split_string = unknown_val.astype(str).str.cat(sep=',')\n",
    "            \n",
    "            return [int(x) for x in split_string.split(',')]\n",
    "        except ValueError:\n",
    "            return []\n",
    "    def replace_unknowns_with_nan(df, attributes):\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].replace(lookup_unknown_val(col, attributes), np.nan)\n",
    "        return df\n",
    "    def drop_columns(df, cols):\n",
    "        drop_cols = list(set(df.columns).intersection(set(cols)))\n",
    "        return df.drop(drop_cols, axis=1)\n",
    "\n",
    "    \n",
    "    df = clean_columns_18_19(df)\n",
    "    df = one_hot_encode(df, ['ANREDE_KZ'], True)\n",
    "    df = one_hot_encode(df, ['CAMEO_DEU_2015', 'D19_LETZTER_KAUF_BRANCHE', 'OST_WEST_KZ'], False)\n",
    "    df = replace_unknowns_with_nan(df, attributes)\n",
    "    df = drop_columns(df, drop_cols) # missing columns in descriptions\n",
    "    df = drop_columns(df, missingness_cols) # columns with high missing values\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Calculating columns to drop because of missing data\n",
    "def missing_percentages(df):\n",
    "    missing = pd.DataFrame(df.isna().sum() / df.shape[0]).reset_index()\n",
    "    missing.columns = ['Attribute', 'Missing']\n",
    "    return missing\n",
    "def remove_features_by_missingness(df, threshold=1):\n",
    "    missing = missing_percentages(df)\n",
    "    cols = missing.loc[missing['Missing'] > threshold, 'Attribute'].tolist()\n",
    "    return cols\n",
    "\n",
    "# creating scalers, and scaling dataframes\n",
    "def return_scaled_columns_list(df):\n",
    "    scaled, not_scaled = df.select_dtypes(exclude='uint8').columns.tolist(), df.select_dtypes(include='uint8').columns.tolist()\n",
    "\n",
    "    return scaled, not_scaled\n",
    "\n",
    "def create_scaler(df):\n",
    "    scaled_col_list, non_scaled_col_list = return_scaled_columns_list(df)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[scaled_col_list])\n",
    "    \n",
    "    return scaler\n",
    "def scale_dataframe(df, scaler):\n",
    "    scaled_col_list, non_scaled_col_list = return_scaled_columns_list(df)\n",
    "    scaled_df = pd.DataFrame(scaler.transform(df[scaled_col_list]), columns=scaled_col_list)\n",
    "    \n",
    "    return pd.concat([scaled_df, df[non_scaled_col_list]], axis=1)\n",
    "\n",
    "# createing imputers, and imputing values\n",
    "def create_imputer(df):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    imputer.fit(df)\n",
    "    return imputer\n",
    "def impute_values(df, imputer):\n",
    "    return pd.DataFrame(imputer.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# columns that are to be dropped because of a lack of information in the documentation\n",
    "drop_cols = ['KBA13_ANTG2',\n",
    "             'D19_SCHUHE',\n",
    "             'D19_REISEN',\n",
    "             'D19_VERSI_ONLINE_DATUM',\n",
    "             'ALTER_KIND3',\n",
    "             'KBA13_ANTG1',\n",
    "             'D19_BANKEN_REST',\n",
    "             'STRUKTURTYP',\n",
    "             'CJT_TYP_5',\n",
    "             'D19_TELKO_REST',\n",
    "             'D19_SONSTIGE',\n",
    "             'EINGEZOGENAM_HH_JAHR',\n",
    "             'D19_BEKLEIDUNG_REST',\n",
    "             'D19_ENERGIE',\n",
    "             'GEMEINDETYP',\n",
    "             'D19_KOSMETIK',\n",
    "             'D19_WEIN_FEINKOST',\n",
    "             'ALTER_KIND4',\n",
    "             'KBA13_HHZ',\n",
    "             'LNR',\n",
    "             'D19_SAMMELARTIKEL',\n",
    "             'D19_BANKEN_DIREKT',\n",
    "             'ANZ_KINDER',\n",
    "             'D19_LOTTO',\n",
    "             'DSL_FLAG',\n",
    "             'UNGLEICHENN_FLAG',\n",
    "             'D19_VERSI_DATUM',\n",
    "             'D19_RATGEBER',\n",
    "             'D19_GARTEN',\n",
    "             'D19_BUCH_CD',\n",
    "             'RT_SCHNAEPPCHEN',\n",
    "             'RT_UEBERGROESSE',\n",
    "             'D19_BEKLEIDUNG_GEH',\n",
    "             'KBA13_BAUMAX',\n",
    "             'D19_BANKEN_LOKAL',\n",
    "             'ALTER_KIND1',\n",
    "             'D19_VERSI_ONLINE_QUOTE_12',\n",
    "             'VHN',\n",
    "             'D19_LEBENSMITTEL',\n",
    "             'VK_ZG11',\n",
    "             'D19_HANDWERK',\n",
    "             'VERDICHTUNGSRAUM',\n",
    "             'KOMBIALTER',\n",
    "             'KONSUMZELLE',\n",
    "             'D19_VOLLSORTIMENT',\n",
    "             'CJT_TYP_4',\n",
    "             'D19_TIERARTIKEL',\n",
    "             'D19_VERSAND_REST',\n",
    "             'D19_BIO_OEKO',\n",
    "             'MOBI_RASTER',\n",
    "             'UMFELD_ALT',\n",
    "             'KBA13_ANTG4',\n",
    "             'CJT_KATALOGNUTZER',\n",
    "             'D19_NAHRUNGSERGAENZUNG',\n",
    "             'CJT_TYP_2',\n",
    "             'KBA13_KMH_210',\n",
    "             'SOHO_KZ',\n",
    "             'EINGEFUEGT_AM',\n",
    "             'D19_TELKO_ONLINE_QUOTE_12',\n",
    "             'CJT_TYP_3',\n",
    "             'CJT_TYP_1',\n",
    "             'ARBEIT',\n",
    "             'D19_BANKEN_GROSS',\n",
    "             'AKT_DAT_KL',\n",
    "             'KBA13_GBZ',\n",
    "             'VK_DISTANZ',\n",
    "             'UMFELD_JUNG',\n",
    "             'ANZ_STATISTISCHE_HAUSHALTE',\n",
    "             'FIRMENDICHTE',\n",
    "             'CJT_TYP_6',\n",
    "             'D19_DROGERIEARTIKEL',\n",
    "             'ALTER_KIND2',\n",
    "             'D19_BILDUNG',\n",
    "             'D19_DIGIT_SERV',\n",
    "             'D19_KINDERARTIKEL',\n",
    "             'HH_DELTA_FLAG',\n",
    "             'EXTSEL992',\n",
    "             'D19_TECHNIK',\n",
    "             'RT_KEIN_ANREIZ',\n",
    "             'D19_SOZIALES',\n",
    "             'D19_TELKO_MOBILE',\n",
    "             'KBA13_CCM_1401_2500',\n",
    "             'ALTERSKATEGORIE_FEIN',\n",
    "             'D19_FREIZEIT',\n",
    "             'VK_DHT4A',\n",
    "             'KBA13_ANTG3',\n",
    "             'D19_KONSUMTYP_MAX',\n",
    "             'VHA',\n",
    "             'D19_VERSI_OFFLINE_DATUM',\n",
    "             'D19_VERSICHERUNGEN',\n",
    "             'KK_KUNDENTYP',\n",
    "             'CAMEO_INTL_2015',\n",
    "             'D19_HAUS_DEKO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mailout_train[['RESPONSE']]\n",
    "X = mailout_train.drop('RESPONSE', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_ml_pipeline(df, azdias_cleaned, attributes, drop_cols):\n",
    "    missingness_cols = remove_features_by_missingness(primary_df, 0.2)\n",
    "    primary_cleaned = clean_dataframe(primary_df, attributes, drop_cols, missingness_cols)\n",
    "    secondary_cleaned = clean_dataframe(secondary_df, attributes, drop_cols, missingness_cols)\n",
    "    scaler = create_scaler(primary_cleaned)\n",
    "    primary_scaled = scale_dataframe(primary_cleaned, scaler)\n",
    "    secondary_scaled = scale_dataframe(secondary_cleaned, scaler)\n",
    "    imputer = create_imputer(primary_scaled)\n",
    "    primary_final = impute_values(primary_scaled, imputer)\n",
    "    secondary_final = impute_values(secondary_scaled, imputer)\n",
    "    \n",
    "    return primary_final, secondary_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._split.StratifiedShuffleSplit"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
