{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data from either source csv or from cleaned cache. Six (6) files\n",
    "    are expected\n",
    "        * data/arvato_data/Udacity_AZDIAS_052018.csv\n",
    "        * data/arvato_data/Udacity_CUSTOMERS_052018.csv\n",
    "        * data/arvato_data/Udacity_MAILOUT_052018_TEST.csv\n",
    "        * data/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv\n",
    "        \n",
    "        * data/DIAS Attributes - Values 2017.xlsx\n",
    "        * data/DIAS Information Levels - Attributes 2017.xlsx\n",
    "    \n",
    "    Returns:\n",
    "        azdias, customer, mailout_test, mailout_train, attributes, information\n",
    "    \"\"\"\n",
    "    def only_named_columns(col):\n",
    "        \"\"\"\n",
    "        Removes columns from DataFrame while loaded that are unnamed\n",
    "        \"\"\"\n",
    "        return 'Unnamed' not in col\n",
    "    \n",
    "    # Attributes and Information\n",
    "    \n",
    "    attributes = pd.read_excel('data/DIAS Attributes - Values 2017.xlsx', header=1, usecols=only_named_columns)\n",
    "    attributes[['Attribute', 'Description']] = attributes[['Attribute', 'Description']].ffill()\n",
    "    \n",
    "    information = pd.read_excel('data/DIAS Information Levels - Attributes 2017.xlsx', header=1, usecols=only_named_columns)\n",
    "    \n",
    "    print('loading azdias data...')\n",
    "    azdias = pd.read_csv('data/arvato_data/Udacity_AZDIAS_052018.csv', sep=';', usecols=only_named_columns)\n",
    "    print('loading customers data...')\n",
    "    customers = pd.read_csv('data/arvato_data/Udacity_CUSTOMERS_052018.csv', sep=';', usecols=only_named_columns)\n",
    "    print('loading mailout test data')\n",
    "    mailout_test = pd.read_csv('data/arvato_data/Udacity_MAILOUT_052018_TEST.csv', sep=';', usecols=only_named_columns)\n",
    "    print('loading mailout training data')\n",
    "    mailout_train = pd.read_csv('data/arvato_data/Udacity_MAILOUT_052018_TRAIN.csv', sep=';', usecols=only_named_columns)\n",
    "    \n",
    "    print('Returning data in this order: azdias, customers, mailout_test, mailout_train, attributes, information')\n",
    "\n",
    "    return azdias, customers, mailout_test, mailout_train, attributes, information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading azdias data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3263: DtypeWarning: Columns (18,19) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading customers data...\n",
      "loading mailout test data\n",
      "loading mailout training data\n",
      "Returning data in this order: azdias, customers, mailout_test, mailout_train, attributes, information\n"
     ]
    }
   ],
   "source": [
    "azdias, customers, mailout_test, mailout_train, attributes, information = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataframe(df, attributes, drop_cols, missingness_cols):\n",
    "    def clean_columns_18_19(df):\n",
    "        columns = ['CAMEO_DEUG_2015', 'CAMEO_INTL_2015']\n",
    "        df[columns] = df.loc[:, columns].replace(['X', 'XX'], np.nan)\n",
    "        df[columns] = df.loc[:, columns].astype(float)\n",
    "        return df\n",
    "    def ost_west_encoder(df):\n",
    "        encoder = {\n",
    "            'O': 0,\n",
    "            'W': 1\n",
    "        }\n",
    "        df['OST_WEST_KZ'] = df['OST_WEST_KZ'].map(encoder)\n",
    "        return df\n",
    "    def male_encoder(df):\n",
    "        encoder = {\n",
    "            2: 0,\n",
    "            1: 1\n",
    "        }\n",
    "        df['ANREDE_KZ'] = df['ANREDE_KZ'].map(encoder)\n",
    "        return df\n",
    "    def one_hot_encode(df, col, drop_first=False):\n",
    "        dummies = pd.get_dummies(df[col], drop_first=drop_first)\n",
    "        df_list = [df.drop(col, axis=1), dummies]\n",
    "        return pd.concat(df_list, axis=1)\n",
    "    def lookup_unknown_val(col, attributes):\n",
    "        try:\n",
    "            mask = (attributes['Attribute'] == col) & (attributes['Meaning'].str.startswith('unknown'))\n",
    "            unknown_val = attributes.loc[mask, 'Value']\n",
    "            split_string = unknown_val.astype(str).str.cat(sep=',')\n",
    "            \n",
    "            return [int(x) for x in split_string.split(',')]\n",
    "        except ValueError:\n",
    "            return []\n",
    "    def replace_unknowns_with_nan(df, attributes):\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].replace(lookup_unknown_val(col, attributes), np.nan)\n",
    "        return df\n",
    "    def drop_columns(df, cols):\n",
    "        drop_cols = list(set(df.columns).intersection(set(cols)))\n",
    "        return df.drop(drop_cols, axis=1)\n",
    "\n",
    "    \n",
    "    df = clean_columns_18_19(df)\n",
    "    df = one_hot_encode(df, ['ANREDE_KZ'], True)\n",
    "    df = one_hot_encode(df, ['CAMEO_DEU_2015', 'D19_LETZTER_KAUF_BRANCHE', 'OST_WEST_KZ'], False)\n",
    "    df = replace_unknowns_with_nan(df, attributes)\n",
    "    df = drop_columns(df, drop_cols) # missing columns in descriptions\n",
    "    df = drop_columns(df, missingness_cols) # columns with high missing values\n",
    "    \n",
    "    return df\n",
    "\n",
    "# def scale_dataframes(df_list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_percentages(df):\n",
    "    missing = pd.DataFrame(df.isna().sum() / df.shape[0]).reset_index()\n",
    "    missing.columns = ['Attribute', 'Missing']\n",
    "    return missing\n",
    "def remove_features_by_missingness(df, threshold=1):\n",
    "    missing = missing_percentages(df)\n",
    "    cols = missing.loc[missing['Missing'] > threshold, 'Attribute'].tolist()\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingness_cols = remove_features_by_missingness(azdias, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns that are to be dropped because of a lack of information in the documentation\n",
    "drop_cols = ['KBA13_ANTG2',\n",
    "             'D19_SCHUHE',\n",
    "             'D19_REISEN',\n",
    "             'D19_VERSI_ONLINE_DATUM',\n",
    "             'ALTER_KIND3',\n",
    "             'KBA13_ANTG1',\n",
    "             'D19_BANKEN_REST',\n",
    "             'STRUKTURTYP',\n",
    "             'CJT_TYP_5',\n",
    "             'D19_TELKO_REST',\n",
    "             'D19_SONSTIGE',\n",
    "             'EINGEZOGENAM_HH_JAHR',\n",
    "             'D19_BEKLEIDUNG_REST',\n",
    "             'D19_ENERGIE',\n",
    "             'GEMEINDETYP',\n",
    "             'D19_KOSMETIK',\n",
    "             'D19_WEIN_FEINKOST',\n",
    "             'ALTER_KIND4',\n",
    "             'KBA13_HHZ',\n",
    "             'LNR',\n",
    "             'D19_SAMMELARTIKEL',\n",
    "             'D19_BANKEN_DIREKT',\n",
    "             'ANZ_KINDER',\n",
    "             'D19_LOTTO',\n",
    "             'DSL_FLAG',\n",
    "             'UNGLEICHENN_FLAG',\n",
    "             'D19_VERSI_DATUM',\n",
    "             'D19_RATGEBER',\n",
    "             'D19_GARTEN',\n",
    "             'D19_BUCH_CD',\n",
    "             'RT_SCHNAEPPCHEN',\n",
    "             'RT_UEBERGROESSE',\n",
    "             'D19_BEKLEIDUNG_GEH',\n",
    "             'KBA13_BAUMAX',\n",
    "             'D19_BANKEN_LOKAL',\n",
    "             'ALTER_KIND1',\n",
    "             'D19_VERSI_ONLINE_QUOTE_12',\n",
    "             'VHN',\n",
    "             'D19_LEBENSMITTEL',\n",
    "             'VK_ZG11',\n",
    "             'D19_HANDWERK',\n",
    "             'VERDICHTUNGSRAUM',\n",
    "             'KOMBIALTER',\n",
    "             'KONSUMZELLE',\n",
    "             'D19_VOLLSORTIMENT',\n",
    "             'CJT_TYP_4',\n",
    "             'D19_TIERARTIKEL',\n",
    "             'D19_VERSAND_REST',\n",
    "             'D19_BIO_OEKO',\n",
    "             'MOBI_RASTER',\n",
    "             'UMFELD_ALT',\n",
    "             'KBA13_ANTG4',\n",
    "             'CJT_KATALOGNUTZER',\n",
    "             'D19_NAHRUNGSERGAENZUNG',\n",
    "             'CJT_TYP_2',\n",
    "             'KBA13_KMH_210',\n",
    "             'SOHO_KZ',\n",
    "             'EINGEFUEGT_AM',\n",
    "             'D19_TELKO_ONLINE_QUOTE_12',\n",
    "             'CJT_TYP_3',\n",
    "             'CJT_TYP_1',\n",
    "             'ARBEIT',\n",
    "             'D19_BANKEN_GROSS',\n",
    "             'AKT_DAT_KL',\n",
    "             'KBA13_GBZ',\n",
    "             'VK_DISTANZ',\n",
    "             'UMFELD_JUNG',\n",
    "             'ANZ_STATISTISCHE_HAUSHALTE',\n",
    "             'FIRMENDICHTE',\n",
    "             'CJT_TYP_6',\n",
    "             'D19_DROGERIEARTIKEL',\n",
    "             'ALTER_KIND2',\n",
    "             'D19_BILDUNG',\n",
    "             'D19_DIGIT_SERV',\n",
    "             'D19_KINDERARTIKEL',\n",
    "             'HH_DELTA_FLAG',\n",
    "             'EXTSEL992',\n",
    "             'D19_TECHNIK',\n",
    "             'RT_KEIN_ANREIZ',\n",
    "             'D19_SOZIALES',\n",
    "             'D19_TELKO_MOBILE',\n",
    "             'KBA13_CCM_1401_2500',\n",
    "             'ALTERSKATEGORIE_FEIN',\n",
    "             'D19_FREIZEIT',\n",
    "             'VK_DHT4A',\n",
    "             'KBA13_ANTG3',\n",
    "             'D19_KONSUMTYP_MAX',\n",
    "             'VHA',\n",
    "             'D19_VERSI_OFFLINE_DATUM',\n",
    "             'D19_VERSICHERUNGEN',\n",
    "             'KK_KUNDENTYP',\n",
    "             'CAMEO_INTL_2015',\n",
    "             'D19_HAUS_DEKO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_specific_columns = ['ONLINE_PURCHASE', 'PRODUCT_GROUP', 'CUSTOMER_GROUP']\n",
    "customer_specific_col_df = customers[customer_specific_columns]\n",
    "customer_similar_col_df = customers.drop(customer_specific_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_customer = clean_dataframe(customer_similar_col_df, attributes, drop_cols, missingness_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_azdias = clean_dataframe(azdias, attributes, drop_cols, missingness_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_scaled_columns_list(df):\n",
    "    scaled, not_scaled = df.select_dtypes(exclude='uint8').columns.tolist(), df.select_dtypes(include='uint8').columns.tolist()\n",
    "\n",
    "    return scaled, not_scaled\n",
    "\n",
    "def create_scaler(df):\n",
    "    scaled_col_list, non_scaled_col_list = return_scaled_columns_list(df)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df[scaled_col_list])\n",
    "    \n",
    "    return scaler\n",
    "def scale_dataframe(df, scaler):\n",
    "    scaled_col_list, non_scaled_col_list = return_scaled_columns_list(df)\n",
    "    scaled_df = pd.DataFrame(scaler.transform(df[scaled_col_list]), columns=scaled_col_list)\n",
    "    \n",
    "    return pd.concat([scaled_df, df[non_scaled_col_list]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = create_scaler(cleaned_azdias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_scaled = scale_dataframe(cleaned_azdias, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_scaled = scale_dataframe(cleaned_customer, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_imputer(df):\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    imputer.fit(df)\n",
    "    return imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(df, imputer):\n",
    "    return pd.DataFrame(imputer.transform(df), columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = create_imputer(azdias_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "azdias_imputed = impute_values(azdias_scaled, imputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_imputed = impute_values(customer_scaled, imputer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
